use crate::world::generate::generate_column;
use crate::world::palette::{BiomePalette, BlockPalette};
use bevy_app::{App, FixedPreUpdate, Plugin};
use bevy_ecs::entity::Entity;
use bevy_ecs::prelude::{Query, Resource, With, resource_exists};
use bevy_ecs::schedule::IntoScheduleConfigs;
use bevy_ecs::system::{Commands, Res, ResMut};
use bevy_math::IVec3;
use bevy_tasks::futures_lite::future;
use bevy_tasks::{Task, TaskPool, TaskPoolBuilder, block_on};
use mcrs_engine::entity::physics::Transform;
use mcrs_engine::entity::player::Player;
use mcrs_engine::world::chunk::{ChunkGenerating, ChunkLoaded, ChunkLoading, ChunkPos, ChunkUnloading};
use mcrs_minecraft_worldgen::bevy::{NoiseGeneratorSettingsPlugin, OverworldNoiseRouter};
use rustc_hash::{FxHashMap, FxHashSet};
use std::collections::{BTreeMap, HashMap};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::{Arc, OnceLock};
use tracing::info;

pub struct ChunkPlugin;

impl Plugin for ChunkPlugin {
    fn build(&self, app: &mut App) {
        app.add_plugins(NoiseGeneratorSettingsPlugin);
        CHUNK_TASK_POOL.get_or_init(|| {
            TaskPoolBuilder::new()
                .thread_name("ChunkGen".to_string())
                .num_threads(4)
                .build()
        });
        app.insert_resource(LoadingChunks::default());
        app.add_systems(
            FixedPreUpdate,
            (
                process_generated_chunk,
                load_chunks.run_if(resource_exists::<OverworldNoiseRouter>),
            )
                .chain(),
        );
    }
}

static CHUNK_TASK_POOL: OnceLock<TaskPool> = OnceLock::new();

/// Token for cooperative cancellation of chunk generation tasks.
///
/// The token is cloned and passed to worker tasks. When `cancel()` is called,
/// tasks check `is_cancelled()` between section generations and can exit early.
#[derive(Clone)]
pub struct CancellationToken(Arc<AtomicBool>);

impl CancellationToken {
    /// Create a new uncancelled token.
    pub fn new() -> Self {
        Self(Arc::new(AtomicBool::new(false)))
    }

    /// Signal cancellation to all clones of this token.
    pub fn cancel(&self) {
        self.0.store(true, Ordering::Release);
    }

    /// Check if cancellation has been signaled.
    pub fn is_cancelled(&self) -> bool {
        self.0.load(Ordering::Acquire)
    }
}

impl Default for CancellationToken {
    fn default() -> Self {
        Self::new()
    }
}

/// Sort key for the priority queue. Lower distance_sq values are dequeued first.
/// The column position (col_x, col_z) serves as a tiebreaker for determinism.
#[derive(Ord, PartialOrd, Eq, PartialEq, Clone, Copy, Debug)]
pub struct ColumnKey {
    /// Squared XZ distance to the nearest player. Primary sort key.
    pub distance_sq: i64,
    /// Column X coordinate. Tiebreaker for deterministic ordering.
    pub col_x: i32,
    /// Column Z coordinate. Tiebreaker for deterministic ordering.
    pub col_z: i32,
}

impl ColumnKey {
    /// Create a new ColumnKey with the given distance and position.
    pub fn new(distance_sq: i64, col_x: i32, col_z: i32) -> Self {
        Self {
            distance_sq,
            col_x,
            col_z,
        }
    }
}

/// A column waiting in the priority queue to be dispatched for generation.
///
/// Contains the list of section entities and their Y positions. Sections are stored
/// as `(Entity, y)` tuples where `y` is the section's Y coordinate.
pub struct PendingColumn {
    /// Section entities with their Y coordinates, to be sorted by Y before dispatch.
    pub sections: Vec<(Entity, i32)>,
}

impl PendingColumn {
    /// Create a new pending column with the given sections.
    pub fn new(sections: Vec<(Entity, i32)>) -> Self {
        Self { sections }
    }
}

/// A column currently being generated by a worker task.
///
/// Tracks the column position, section entities, cancellation token, and the async task.
/// When the task completes or is cancelled, the sections are processed accordingly.
pub struct InFlightColumn {
    /// Column position (x, z) in chunk coordinates.
    pub col: (i32, i32),
    /// Section entities with their Y coordinates.
    pub sections: Vec<(Entity, i32)>,
    /// Token to signal cancellation to the worker task.
    pub cancel: CancellationToken,
    /// The async task generating this column.
    pub task: Task<ChunkColumnResult>,
}

impl InFlightColumn {
    /// Create a new in-flight column with the given parameters.
    pub fn new(
        col: (i32, i32),
        sections: Vec<(Entity, i32)>,
        cancel: CancellationToken,
        task: Task<ChunkColumnResult>,
    ) -> Self {
        Self {
            col,
            sections,
            cancel,
            task,
        }
    }
}

/// Configuration for the chunk column scheduler.
///
/// Controls concurrency limits and dispatch rates for chunk generation tasks.
#[derive(Resource, Clone)]
pub struct SchedulerConfig {
    /// Maximum number of concurrent generation tasks.
    /// Default: `available_parallelism * 2` (or 8 if unavailable).
    pub max_in_flight: usize,
    /// Maximum columns to dispatch per tick.
    /// Default: 32.
    pub max_dispatch_per_tick: usize,
    /// Number of threads in the chunk generation thread pool.
    /// Default: 4.
    pub num_threads: usize,
}

impl Default for SchedulerConfig {
    fn default() -> Self {
        let parallelism = std::thread::available_parallelism()
            .map(|p| p.get())
            .unwrap_or(4);
        Self {
            max_in_flight: parallelism * 2,
            max_dispatch_per_tick: 32,
            num_threads: 4,
        }
    }
}

/// Priority-based scheduler for chunk column generation.
///
/// Manages the lifecycle of chunk columns from pending to in-flight to completed.
/// Uses a `BTreeMap` priority queue for O(log n) priority-ordered dispatch and efficient
/// removal during cancellation/reprioritization.
///
/// # Structure
/// - `pending`: Priority queue of columns waiting to be dispatched (ordered by `ColumnKey`)
/// - `column_index`: Reverse index from column position to its current priority key
/// - `in_flight_index`: Set of column positions currently being generated
/// - `in_flight`: Active generation tasks with their cancellation tokens
/// - `config`: Concurrency and dispatch limits
#[derive(Resource)]
pub struct ChunkColumnScheduler {
    /// Priority queue of pending columns. Lower `ColumnKey` values are dispatched first.
    pub pending: BTreeMap<ColumnKey, PendingColumn>,
    /// Reverse index: column position -> current priority key.
    /// Enables O(log n) removal/reprioritization by position.
    pub column_index: FxHashMap<(i32, i32), ColumnKey>,
    /// Set of column positions with active generation tasks.
    /// Used to avoid duplicate dispatch.
    pub in_flight_index: FxHashSet<(i32, i32)>,
    /// Active generation tasks with cancellation tokens.
    pub in_flight: Vec<InFlightColumn>,
    /// Configuration for concurrency limits and dispatch rates.
    pub config: SchedulerConfig,
}

impl Default for ChunkColumnScheduler {
    fn default() -> Self {
        Self::new(SchedulerConfig::default())
    }
}

impl ChunkColumnScheduler {
    /// Create a new scheduler with the given configuration.
    pub fn new(config: SchedulerConfig) -> Self {
        Self {
            pending: BTreeMap::new(),
            column_index: FxHashMap::default(),
            in_flight_index: FxHashSet::default(),
            in_flight: Vec::new(),
            config,
        }
    }

    /// Returns the number of columns waiting to be dispatched.
    pub fn pending_count(&self) -> usize {
        self.pending.len()
    }

    /// Returns the number of columns currently being generated.
    pub fn in_flight_count(&self) -> usize {
        self.in_flight.len()
    }

    /// Check if a column is pending dispatch.
    pub fn is_pending(&self, col: (i32, i32)) -> bool {
        self.column_index.contains_key(&col)
    }

    /// Check if a column has an active generation task.
    pub fn is_in_flight(&self, col: (i32, i32)) -> bool {
        self.in_flight_index.contains(&col)
    }
}

/// Result of a column generation task.
///
/// Contains the list of generated sections for a column. Each section includes
/// the entity, position, and optionally the generated block/biome data.
/// `None` indicates the section was cancelled before generation could complete.
struct ChunkColumnResult {
    /// Generated sections. `None` for cancelled sections, `Some((blocks, biomes))` for completed.
    sections: Vec<(Entity, ChunkPos, Option<(BlockPalette, BiomePalette)>)>,
}

#[derive(Resource, Default)]
struct LoadingChunks {
    tasks: Vec<Task<ChunkColumnResult>>,
}

/// Squared XZ (column) distance from a chunk to the nearest player.
fn min_column_distance(pos: &ChunkPos, players: &[IVec3]) -> i64 {
    if players.is_empty() {
        return 0;
    }
    players
        .iter()
        .map(|p| {
            let dx = (pos.x - p.x) as i64;
            let dz = (pos.z - p.z) as i64;
            dx * dx + dz * dz
        })
        .min()
        .unwrap_or(0)
}

/// Absolute Y distance from a chunk to the nearest player's Y.
fn min_y_distance(pos: &ChunkPos, players: &[IVec3]) -> i32 {
    if players.is_empty() {
        return 0;
    }
    players
        .iter()
        .map(|p| (pos.y - p.y).abs())
        .min()
        .unwrap_or(0)
}

fn load_chunks(
    mut commands: Commands,
    query: Query<(Entity, &ChunkPos), With<ChunkLoading>>,
    mut loading_chunks: ResMut<LoadingChunks>,
    overworld_noise_router: Res<OverworldNoiseRouter>,
    players: Query<&Transform, With<Player>>,
) {
    if query.is_empty() {
        return;
    }

    let task_pool = CHUNK_TASK_POOL.get().unwrap();

    // Group sections by (x, z) column
    let mut columns: HashMap<(i32, i32), Vec<(Entity, ChunkPos)>> = HashMap::new();
    for (entity, pos) in query.iter() {
        commands
            .entity(entity)
            .insert(ChunkGenerating)
            .remove::<ChunkLoading>();
        columns
            .entry((pos.x, pos.z))
            .or_default()
            .push((entity, *pos));
    }

    let mut dispatched = 0usize;

    for ((col_x, col_z), mut sections) in columns {
        // Sort sections by Y so generation proceeds bottom-to-top
        sections.sort_by_key(|(_, pos)| pos.y);

        let router = overworld_noise_router.0.clone();
        let cancel = CancellationToken::new();
        let task = task_pool.spawn(async move {
            let router = router.as_ref();
            let _span = tracing::info_span!("ChunkColumnGen").entered();

            let y_sections: Vec<i32> = sections.iter().map(|(_, pos)| pos.y).collect();
            let results = generate_column(col_x, col_z, &y_sections, router, &cancel);

            let column_sections = sections
                .into_iter()
                .zip(results)
                .map(|((entity, pos), result)| (entity, pos, result))
                .collect();

            ChunkColumnResult {
                sections: column_sections,
            }
        });

        loading_chunks.tasks.push(task);
        dispatched += 1;
    }

    if dispatched > 0 {
        info!("Dispatched generation tasks for {} columns", dispatched);
    }
}

fn process_generated_chunk(mut loading_chunks: ResMut<LoadingChunks>, mut commands: Commands) {
    loading_chunks.tasks.retain_mut(|task| {
        let res = block_on(future::poll_once(task));
        if let Some(column_result) = res {
            for (entity, _pos, result) in column_result.sections {
                match result {
                    Some((blocks, biomes)) => {
                        // Section completed successfully
                        commands
                            .entity(entity)
                            .insert((ChunkLoaded, blocks, biomes))
                            .remove::<ChunkGenerating>();
                    }
                    None => {
                        // Section was cancelled before generation
                        commands
                            .entity(entity)
                            .insert(ChunkUnloading)
                            .remove::<ChunkGenerating>();
                    }
                }
            }
            false
        } else {
            true
        }
    });
}
