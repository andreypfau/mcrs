use crate::world::generate::generate_column;
use crate::world::palette::{BiomePalette, BlockPalette};
use bevy_app::{App, FixedPreUpdate, Plugin};
use bevy_ecs::entity::Entity;
use bevy_ecs::prelude::{Query, Resource, With, resource_exists};
use bevy_ecs::schedule::IntoScheduleConfigs;
use bevy_ecs::system::{Commands, Res, ResMut};
use bevy_math::IVec3;
use bevy_tasks::futures_lite::future;
use bevy_tasks::{Task, TaskPool, TaskPoolBuilder, block_on};
use mcrs_engine::entity::physics::Transform;
use mcrs_engine::entity::player::chunk_view::PlayerChunkObserver;
use mcrs_engine::entity::player::Player;
use mcrs_engine::world::chunk::{ChunkGenerating, ChunkLoaded, ChunkLoading, ChunkPos, ChunkUnloading};
use mcrs_minecraft_worldgen::bevy::{NoiseGeneratorSettingsPlugin, OverworldNoiseRouter};
use rustc_hash::{FxHashMap, FxHashSet};
use std::collections::{BTreeMap, HashMap};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::{Arc, OnceLock};
use tracing::info;

pub struct ChunkPlugin;

impl Plugin for ChunkPlugin {
    fn build(&self, app: &mut App) {
        app.add_plugins(NoiseGeneratorSettingsPlugin);
        CHUNK_TASK_POOL.get_or_init(|| {
            TaskPoolBuilder::new()
                .thread_name("ChunkGen".to_string())
                .num_threads(4)
                .build()
        });
        app.insert_resource(LoadingChunks::default());
        app.add_systems(
            FixedPreUpdate,
            (
                process_generated_chunk,
                load_chunks.run_if(resource_exists::<OverworldNoiseRouter>),
            )
                .chain(),
        );
    }
}

static CHUNK_TASK_POOL: OnceLock<TaskPool> = OnceLock::new();

/// Token for cooperative cancellation of chunk generation tasks.
///
/// The token is cloned and passed to worker tasks. When `cancel()` is called,
/// tasks check `is_cancelled()` between section generations and can exit early.
#[derive(Clone)]
pub struct CancellationToken(Arc<AtomicBool>);

impl CancellationToken {
    /// Create a new uncancelled token.
    pub fn new() -> Self {
        Self(Arc::new(AtomicBool::new(false)))
    }

    /// Signal cancellation to all clones of this token.
    pub fn cancel(&self) {
        self.0.store(true, Ordering::Release);
    }

    /// Check if cancellation has been signaled.
    pub fn is_cancelled(&self) -> bool {
        self.0.load(Ordering::Acquire)
    }
}

impl Default for CancellationToken {
    fn default() -> Self {
        Self::new()
    }
}

/// Sort key for the priority queue. Lower distance_sq values are dequeued first.
/// The column position (col_x, col_z) serves as a tiebreaker for determinism.
#[derive(Ord, PartialOrd, Eq, PartialEq, Clone, Copy, Debug)]
pub struct ColumnKey {
    /// Squared XZ distance to the nearest player. Primary sort key.
    pub distance_sq: i64,
    /// Column X coordinate. Tiebreaker for deterministic ordering.
    pub col_x: i32,
    /// Column Z coordinate. Tiebreaker for deterministic ordering.
    pub col_z: i32,
}

impl ColumnKey {
    /// Create a new ColumnKey with the given distance and position.
    pub fn new(distance_sq: i64, col_x: i32, col_z: i32) -> Self {
        Self {
            distance_sq,
            col_x,
            col_z,
        }
    }
}

/// A column waiting in the priority queue to be dispatched for generation.
///
/// Contains the list of section entities and their Y positions. Sections are stored
/// as `(Entity, y)` tuples where `y` is the section's Y coordinate.
pub struct PendingColumn {
    /// Section entities with their Y coordinates, to be sorted by Y before dispatch.
    pub sections: Vec<(Entity, i32)>,
}

impl PendingColumn {
    /// Create a new pending column with the given sections.
    pub fn new(sections: Vec<(Entity, i32)>) -> Self {
        Self { sections }
    }
}

/// A column currently being generated by a worker task.
///
/// Tracks the column position, section entities, cancellation token, and the async task.
/// When the task completes or is cancelled, the sections are processed accordingly.
pub struct InFlightColumn {
    /// Column position (x, z) in chunk coordinates.
    pub col: (i32, i32),
    /// Section entities with their Y coordinates.
    pub sections: Vec<(Entity, i32)>,
    /// Token to signal cancellation to the worker task.
    pub cancel: CancellationToken,
    /// The async task generating this column.
    pub task: Task<ChunkColumnResult>,
}

impl InFlightColumn {
    /// Create a new in-flight column with the given parameters.
    pub fn new(
        col: (i32, i32),
        sections: Vec<(Entity, i32)>,
        cancel: CancellationToken,
        task: Task<ChunkColumnResult>,
    ) -> Self {
        Self {
            col,
            sections,
            cancel,
            task,
        }
    }
}

/// Configuration for the chunk column scheduler.
///
/// Controls concurrency limits and dispatch rates for chunk generation tasks.
#[derive(Resource, Clone)]
pub struct SchedulerConfig {
    /// Maximum number of concurrent generation tasks.
    /// Default: `available_parallelism * 2` (or 8 if unavailable).
    pub max_in_flight: usize,
    /// Maximum columns to dispatch per tick.
    /// Default: 32.
    pub max_dispatch_per_tick: usize,
    /// Number of threads in the chunk generation thread pool.
    /// Default: 4.
    pub num_threads: usize,
}

impl Default for SchedulerConfig {
    fn default() -> Self {
        let parallelism = std::thread::available_parallelism()
            .map(|p| p.get())
            .unwrap_or(4);
        Self {
            max_in_flight: parallelism * 2,
            max_dispatch_per_tick: 32,
            num_threads: 4,
        }
    }
}

/// Priority-based scheduler for chunk column generation.
///
/// Manages the lifecycle of chunk columns from pending to in-flight to completed.
/// Uses a `BTreeMap` priority queue for O(log n) priority-ordered dispatch and efficient
/// removal during cancellation/reprioritization.
///
/// # Structure
/// - `pending`: Priority queue of columns waiting to be dispatched (ordered by `ColumnKey`)
/// - `column_index`: Reverse index from column position to its current priority key
/// - `in_flight_index`: Set of column positions currently being generated
/// - `in_flight`: Active generation tasks with their cancellation tokens
/// - `config`: Concurrency and dispatch limits
#[derive(Resource)]
pub struct ChunkColumnScheduler {
    /// Priority queue of pending columns. Lower `ColumnKey` values are dispatched first.
    pub pending: BTreeMap<ColumnKey, PendingColumn>,
    /// Reverse index: column position -> current priority key.
    /// Enables O(log n) removal/reprioritization by position.
    pub column_index: FxHashMap<(i32, i32), ColumnKey>,
    /// Set of column positions with active generation tasks.
    /// Used to avoid duplicate dispatch.
    pub in_flight_index: FxHashSet<(i32, i32)>,
    /// Active generation tasks with cancellation tokens.
    pub in_flight: Vec<InFlightColumn>,
    /// Configuration for concurrency limits and dispatch rates.
    pub config: SchedulerConfig,
}

impl Default for ChunkColumnScheduler {
    fn default() -> Self {
        Self::new(SchedulerConfig::default())
    }
}

impl ChunkColumnScheduler {
    /// Create a new scheduler with the given configuration.
    pub fn new(config: SchedulerConfig) -> Self {
        Self {
            pending: BTreeMap::new(),
            column_index: FxHashMap::default(),
            in_flight_index: FxHashSet::default(),
            in_flight: Vec::new(),
            config,
        }
    }

    /// Returns the number of columns waiting to be dispatched.
    pub fn pending_count(&self) -> usize {
        self.pending.len()
    }

    /// Returns the number of columns currently being generated.
    pub fn in_flight_count(&self) -> usize {
        self.in_flight.len()
    }

    /// Check if a column is pending dispatch.
    pub fn is_pending(&self, col: (i32, i32)) -> bool {
        self.column_index.contains_key(&col)
    }

    /// Check if a column has an active generation task.
    pub fn is_in_flight(&self, col: (i32, i32)) -> bool {
        self.in_flight_index.contains(&col)
    }
}

/// Result of a column generation task.
///
/// Contains the list of generated sections for a column. Each section includes
/// the entity, position, and optionally the generated block/biome data.
/// `None` indicates the section was cancelled before generation could complete.
struct ChunkColumnResult {
    /// Generated sections. `None` for cancelled sections, `Some((blocks, biomes))` for completed.
    sections: Vec<(Entity, ChunkPos, Option<(BlockPalette, BiomePalette)>)>,
}

#[derive(Resource, Default)]
struct LoadingChunks {
    tasks: Vec<Task<ChunkColumnResult>>,
}

/// Squared XZ (column) distance from a chunk to the nearest player.
fn min_column_distance(pos: &ChunkPos, players: &[IVec3]) -> i64 {
    if players.is_empty() {
        return 0;
    }
    players
        .iter()
        .map(|p| {
            let dx = (pos.x - p.x) as i64;
            let dz = (pos.z - p.z) as i64;
            dx * dx + dz * dz
        })
        .min()
        .unwrap_or(0)
}

/// Absolute Y distance from a chunk to the nearest player's Y.
fn min_y_distance(pos: &ChunkPos, players: &[IVec3]) -> i32 {
    if players.is_empty() {
        return 0;
    }
    players
        .iter()
        .map(|p| (pos.y - p.y).abs())
        .min()
        .unwrap_or(0)
}

fn load_chunks(
    mut commands: Commands,
    query: Query<(Entity, &ChunkPos), With<ChunkLoading>>,
    mut loading_chunks: ResMut<LoadingChunks>,
    overworld_noise_router: Res<OverworldNoiseRouter>,
    players: Query<&Transform, With<Player>>,
) {
    if query.is_empty() {
        return;
    }

    let task_pool = CHUNK_TASK_POOL.get().unwrap();

    // Group sections by (x, z) column
    let mut columns: HashMap<(i32, i32), Vec<(Entity, ChunkPos)>> = HashMap::new();
    for (entity, pos) in query.iter() {
        commands
            .entity(entity)
            .insert(ChunkGenerating)
            .remove::<ChunkLoading>();
        columns
            .entry((pos.x, pos.z))
            .or_default()
            .push((entity, *pos));
    }

    let mut dispatched = 0usize;

    for ((col_x, col_z), mut sections) in columns {
        // Sort sections by Y so generation proceeds bottom-to-top
        sections.sort_by_key(|(_, pos)| pos.y);

        let router = overworld_noise_router.0.clone();
        let cancel = CancellationToken::new();
        let task = task_pool.spawn(async move {
            let router = router.as_ref();
            let _span = tracing::info_span!("ChunkColumnGen").entered();

            let y_sections: Vec<i32> = sections.iter().map(|(_, pos)| pos.y).collect();
            let results = generate_column(col_x, col_z, &y_sections, router, &cancel);

            let column_sections = sections
                .into_iter()
                .zip(results)
                .map(|((entity, pos), result)| (entity, pos, result))
                .collect();

            ChunkColumnResult {
                sections: column_sections,
            }
        });

        loading_chunks.tasks.push(task);
        dispatched += 1;
    }

    if dispatched > 0 {
        info!("Dispatched generation tasks for {} columns", dispatched);
    }
}

fn process_generated_chunk(mut loading_chunks: ResMut<LoadingChunks>, mut commands: Commands) {
    loading_chunks.tasks.retain_mut(|task| {
        let res = block_on(future::poll_once(task));
        if let Some(column_result) = res {
            for (entity, _pos, result) in column_result.sections {
                match result {
                    Some((blocks, biomes)) => {
                        // Section completed successfully
                        commands
                            .entity(entity)
                            .insert((ChunkLoaded, blocks, biomes))
                            .remove::<ChunkGenerating>();
                    }
                    None => {
                        // Section was cancelled before generation
                        commands
                            .entity(entity)
                            .insert(ChunkUnloading)
                            .remove::<ChunkGenerating>();
                    }
                }
            }
            false
        } else {
            true
        }
    });
}

/// Process completed column generation tasks from the scheduler.
///
/// This system polls in-flight tasks and processes their results:
/// - For successfully completed sections: inserts `ChunkLoaded` with block/biome data
/// - For cancelled sections (None): inserts `ChunkUnloading` to trigger cleanup
/// - Removes `ChunkGenerating` marker from all processed sections
/// - Removes completed columns from the `in_flight_index`
///
/// Uses `retain_mut` pattern to efficiently filter completed tasks while iterating.
fn process_completed_columns(
    mut scheduler: ResMut<ChunkColumnScheduler>,
    mut commands: Commands,
) {
    scheduler.in_flight.retain_mut(|in_flight| {
        let res = block_on(future::poll_once(&mut in_flight.task));
        if let Some(column_result) = res {
            // Column generation task completed, process all sections
            for (entity, _pos, result) in column_result.sections {
                match result {
                    Some((blocks, biomes)) => {
                        // Section completed successfully - mark as loaded with data
                        commands
                            .entity(entity)
                            .insert((ChunkLoaded, blocks, biomes))
                            .remove::<ChunkGenerating>();
                    }
                    None => {
                        // Section was cancelled before generation could complete
                        // Mark for unloading so the entity gets cleaned up
                        commands
                            .entity(entity)
                            .insert(ChunkUnloading)
                            .remove::<ChunkGenerating>();
                    }
                }
            }
            // Remove column from in-flight tracking
            scheduler.in_flight_index.remove(&in_flight.col);
            false // Remove from in_flight Vec
        } else {
            true // Keep in in_flight Vec, task still running
        }
    });
}

/// Enqueue pending chunk columns from entities with ChunkLoading marker.
///
/// This system:
/// 1. Queries all entities with `ChunkLoading` component (newly requested sections)
/// 2. Groups sections by their (x, z) column position
/// 3. Computes priority based on squared XZ distance to nearest player
/// 4. Inserts columns into the priority queue with their priority key
/// 5. Transitions entities from `ChunkLoading` to `ChunkGenerating` state
///
/// Columns already pending or in-flight are skipped to avoid duplicate work.
/// The `ChunkGenerating` marker is applied immediately to prevent re-discovery
/// on subsequent ticks.
fn enqueue_pending_columns(
    mut commands: Commands,
    mut scheduler: ResMut<ChunkColumnScheduler>,
    loading_query: Query<(Entity, &ChunkPos), With<ChunkLoading>>,
    players: Query<&Transform, With<Player>>,
) {
    if loading_query.is_empty() {
        return;
    }

    // Collect player positions for distance calculations
    let player_positions: Vec<IVec3> = players
        .iter()
        .map(|t| {
            // Convert world position to chunk coordinates
            IVec3::new(
                (t.position.x / 16.0).floor() as i32,
                (t.position.y / 16.0).floor() as i32,
                (t.position.z / 16.0).floor() as i32,
            )
        })
        .collect();

    // Group sections by (x, z) column
    let mut columns: HashMap<(i32, i32), Vec<(Entity, i32)>> = HashMap::new();
    for (entity, pos) in loading_query.iter() {
        // Transition entity state: ChunkLoading -> ChunkGenerating
        // This prevents re-discovery on subsequent ticks
        commands
            .entity(entity)
            .insert(ChunkGenerating)
            .remove::<ChunkLoading>();

        columns
            .entry((pos.x, pos.z))
            .or_default()
            .push((entity, pos.y));
    }

    // Enqueue each new column into the priority queue
    for ((col_x, col_z), sections) in columns {
        let col = (col_x, col_z);

        // Skip columns that are already pending or in-flight
        if scheduler.is_pending(col) || scheduler.is_in_flight(col) {
            continue;
        }

        // Compute priority: squared XZ distance to nearest player
        // Create a ChunkPos for distance calculation (Y doesn't matter for XZ distance)
        let chunk_pos = ChunkPos::new(col_x, 0, col_z);
        let distance_sq = min_column_distance(&chunk_pos, &player_positions);

        // Create the priority key and pending column
        let key = ColumnKey::new(distance_sq, col_x, col_z);
        let pending_column = PendingColumn::new(sections);

        // Insert into priority queue and reverse index
        scheduler.pending.insert(key, pending_column);
        scheduler.column_index.insert(col, key);
    }
}

/// Cancel columns that are no longer within any player's view.
///
/// This system handles cancellation for both pending and in-flight columns:
///
/// **Pending columns:**
/// - Removed from the priority queue and column index
/// - All sections transitioned from `ChunkGenerating` to `ChunkUnloading`
///
/// **In-flight columns:**
/// - Cancellation token signaled via `cancel.cancel()`
/// - The worker task will check `is_cancelled()` between sections and exit early
/// - `process_completed_columns` will handle the partial results on the next tick
///
/// A column is considered "stale" if NONE of its sections are visible to ANY player.
/// This is a conservative check - if even one section might be visible, we keep the column.
fn cancel_stale_columns(
    mut scheduler: ResMut<ChunkColumnScheduler>,
    mut commands: Commands,
    players: Query<&PlayerChunkObserver>,
) {
    // Collect all player views for visibility checks
    let player_views: Vec<_> = players
        .iter()
        .filter_map(|observer| observer.last_last_chunk_tracking_view)
        .collect();

    // If no players have views, don't cancel anything (edge case during startup)
    if player_views.is_empty() {
        return;
    }

    // Helper closure: check if a column has any section visible to any player
    let is_column_visible = |col: (i32, i32), sections: &[(Entity, i32)]| -> bool {
        for (_, section_y) in sections {
            let chunk_pos = ChunkPos::new(col.0, *section_y, col.1);
            for view in &player_views {
                if view.contains(&chunk_pos) {
                    return true;
                }
            }
        }
        false
    };

    // Cancel stale pending columns
    // Collect keys to remove first to avoid borrowing issues
    let stale_pending: Vec<((i32, i32), ColumnKey, Vec<Entity>)> = scheduler
        .column_index
        .iter()
        .filter_map(|(col, key)| {
            let pending = scheduler.pending.get(key)?;
            if !is_column_visible(*col, &pending.sections) {
                // Collect section entities for cleanup
                let entities: Vec<Entity> = pending.sections.iter().map(|(e, _)| *e).collect();
                Some((*col, *key, entities))
            } else {
                None
            }
        })
        .collect();

    // Remove stale pending columns and mark sections for unloading
    for (col, key, entities) in stale_pending {
        scheduler.pending.remove(&key);
        scheduler.column_index.remove(&col);

        // Transition all sections to ChunkUnloading state
        for entity in entities {
            commands
                .entity(entity)
                .insert(ChunkUnloading)
                .remove::<ChunkGenerating>();
        }
    }

    // Cancel stale in-flight columns
    // For in-flight columns, we just signal cancellation - the worker will check the token
    for in_flight in &scheduler.in_flight {
        if !is_column_visible(in_flight.col, &in_flight.sections) {
            // Signal cancellation to the worker task
            // The task will check is_cancelled() between sections and exit early
            in_flight.cancel.cancel();
        }
    }
}
